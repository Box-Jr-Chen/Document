# 貝葉斯原理

- 官網 https://scikit-learn.org/stable/modules/naive_bayes.html

- 利用概率來進行分類。

 <img src="http://chart.googleapis.com/chart?cht=tx&chl= P(y | x_1, \dots, x_n) = \frac{P(y) P(x_1, \dots, x_n | y)}{P(x_1, \dots, x_n)}" style="border:none;"> 
 
## 樸素貝葉斯

-  樸素貝葉斯方法是一組監督學習算法，基於貝葉斯定理，在給定類變量值的情況下，每對特徵之間具有條件獨立性的“樸素”假設被應用。


範例:
 <img src="樸素貝葉斯範例.jpg" style="border:none;"> 


### 高斯分布

- 實現高斯樸素貝葉斯算法進行分類。

 <img src="http://chart.googleapis.com/chart?cht=tx&chl=P(x_i | y) = \frac{1}{\sqrt{2\pi\sigma^2_y}} \exp\left(-\frac{(x_i - \mu_y)^2}{2\sigma^2_y}\right)" style="border:none;"> 

### 多重分布

- 實現用於多項分佈數據的樸素貝葉斯算法，並且是文本分類中使用的兩個經典樸素貝葉斯變體之一。

- 其中數據通常表示為單詞向量計數，儘管眾所周知tf-idf向量在實踐中也能很好地工作。


###  Bernoulli 二分類法

- 對根據多元伯努利分佈分配的數據實施樸素的貝葉斯訓練和分類算法。

- 即可能有多個特徵，但每個特徵都假定為一個二進制值（伯努利（Bernoulli），布爾值）變量。

- 此類要求將樣本表示為二進制值特徵向量。如果傳遞任何其他類型的數據，則BernoulliNB實例可以將其輸入二進制化（取決於binarize參數）。

